---
title: "Homework2"
author: "Yuqian Liu"
date: "`r format(Sys.time(), '%d %B %Y')`"
documentclass: article
papersize: letter
fontsize: 11pt
output: html_document
---

```{r setup, include=FALSE}
require(knitr)
knitr::opts_chunk$set(echo = TRUE)
source("mainQ1_Yuqian_try2.R")
source("mainQ2_Yuqian.R")
## specify global chunk options
knitr::opts_chunk$set(fig.width = 5, fig.height = 4, dpi = 300,
                      out.width = "90%", fig.align = "center")
```


## Problem 1
**Answer:** 


Cauchy$(\theta ,1)$ distribution has probability density 
$p(x;\theta ) = \frac{1}{{\pi [1 + {{(x - \theta )}^2}]}},$ where
$x \in R$ and $\theta \in R$.

a) The likelihood function of $\theta$ is
$L(x,\theta ) = \prod\limits_{i = 1}^n {p({x_i};\theta )}$.
Then, the log-likelihood is
\begin{align}
\begin{array}{l}
l(\theta ) = \sum\limits_{i = n}^n {\log (p({x_i};\theta ))} \\
 = \sum\limits_{i = n}^n 
 {\log (\frac{1}{{\pi [1 + {{(x - \theta )}^2}]}})} \\
 = \sum\limits_{i = n}^n {[\log \frac{1}{\pi } + 
 \log \frac{1}{{1 + {{(x - \theta )}^2}}}} ]\\
 =  - n\ln \pi  - \sum\limits_{i 
 = n}^n {\ln [1 + {{(\theta  - {x_i})}^2}]} 
\end{array}
\end{align}
Thus, $l'(\theta)$ and $l''(\theta)$ are,
\begin{align}
\begin{array}{l}
l'(\theta ) =  - \sum\limits_{i = n}^n {\frac{{p'({x_i};\theta )}}{{p({x_i};\theta )}}} \\
 =  - \sum\limits_{i = n}^n {[\frac{1}{{1 + 
 {{(\theta  - {x_i})}^2}}} \times 2(\theta  - {x_i})]} \\
 =  - 2\sum\limits_{i = n}^n {\frac{{\theta  - {x_i}}}
 {{1 + {{(\theta  - {x_i})}^2}}}} 
\end{array}
\end{align}

\begin{align}
\begin{array}{l}
l''(\theta ) = \sum\limits_{i = n}^n {\frac{p''(x_i;\theta )}{p(x_i;\theta )}}  
- \sum\limits_{i = n}^n {\{ \frac{p'(x_i;\theta )}{p(x_i;\theta )}} {\} ^2}\\
=  - 2\sum\limits_{i = n}^n {\frac{1 - (\theta  - x_i)^2}{[1 + (\theta  - x_i)^2]^2}} 
\end{array}
\end{align}
The fisher information is
\begin{align}
\begin{array}{l}
I(\theta ) =  - {{\rm E}_\theta }\{ l''(\theta )\} \\
 =  - n{{\rm E}_\theta }[\frac{p''(x_i;\theta )}{p(x_i;\theta )} - 
 {\{ \frac{p'(x_i;\theta )}{p(x_i;\theta )}\} ^2}]\\
 =  - n\int {[\frac{p''(x_i;\theta )}{p(x_i;\theta )} - 
 {{\{ \frac{p'(x_i;\theta )}{p(x_i;\theta )}\} }^2}]p(x_i;\theta )dx} \\
 =  - n\int {\frac{{\{ p'(x)\} }^2}{p(x)}dx} \\
 = \frac{4n}{\pi }\int_{ - \infty }^\infty  {\frac{{{x^2}dx}}{{(1 + x^2)}^3}} \\
 = \frac{n}{2}
\end{array}
\end{align}

b) The observed sample is
```{r, eval = FALSE}
x1 <- c(1.77, -0.23, 2.76, 3.80, 3.47, 56.75, -1.34, 4.24, -2.44,
       3.29, 3.71, -2.40, 4.53, -0.07, -1.05, -13.87, -2.53, -1.75)
```
The log-likelihood function is shown in Figure \@ref(fig:Q1b).

(ref:Q1b) Log-likelihood of Cauchy.

```{r Q1b, echo = TRUE, fig.cap = "(ref:Q1b)", fig.width = 8}
plot(Theta_value, LogLik_plot,xlab = "theta",ylab = "log-likelihood",)
```
Then, Newton-Raphson method with 
```{r, eval = FALSE}
StartPoints <- c(-11, -1, 0, 1.5, 4, 4.7, 7, 8, 38)
```
and sample mean as start points have been applied.
The results are shown in follow.

c) The fixed-point iterations using $G(x)=\alpha l'(\theta)+\theta$
with scaling choices of $\alpha \in \{1, 0.64, 0.25\}$ have also been
applied.
The results are shown as follow.

d) The fisher scoring refined by Newton method has been conducted.
The results are shown as follow.

e) Compare the results from these different methods.

## Problem 2
**Answer:** 


The probability density with parameter $\theta$ is 
$p(x;\theta ){\rm{ }} = {\rm{ }}\frac{{1 - cos(x - \theta )}}{{2\pi }}$,
where $0 \le x \le 2\pi$ and $\theta  \in ( - \pi ,{\rm{ }}\pi )$.

a) The log-likelihood function of $\theta$ is
\begin{align}
\begin{array}{l}
l(\theta ) = \sum\limits_{i = n}^n {\log (p({x_i};\theta ))} \\
 = - 2n\ln \pi  + \sum\limits_{i = n}^n {\ln [1 - cos(x - \theta )]} 
\end{array}
\end{align}
The observed sample is
```{r, eval = FALSE}
x2 <- c(3.91, 4.85, 2.28, 4.06, 3.70, 4.04, 5.46, 3.53, 2.28, 1.96,
       2.53, 3.88, 2.22, 3.47, 4.82, 2.46, 2.99, 2.54, 0.52)
```
The log-likelihood function is shown in Figure \@ref(fig:Q2a).

(ref:Q2a) Log-likelihood Function.

```{r Q2a, echo = FALSE, fig.cap = "(ref:Q2a)", fig.width = 8}
plot(Theta_value2, LogLik_plot2,xlab = "theta",ylab = "log-likelihood")
```

b) Method of moments
\begin{align}
\begin{array}{l}
{\rm E}(X|\theta ) = \int_0^{2\pi } {p(x;\theta )} xdx\\
 =  -\frac{1}{2\pi }[\cos (x - \theta ) - \frac{x^2}{2} + x\sin (x - \theta )]|_0^{2\pi }\\
 = \pi  + \sin \theta 
\end{array}
\end{align}
Thus, ${\hat \theta _{moment}}$ could be calculated based on ${\rm E}(X|\theta ) = \bar x$. 
Solve for $\theta$,
\begin{align}
${\hat \theta _{moment}} = \arcsin (\bar x - \pi )$
\end{align}

c) With $\theta_0 = \hat \theta _{moment}$, using the Newton-Raphson method the MLE is

d) With $\theta_0 = -2.7$ and $\theta_0 = 2.7$, the results are

e) Repeat the above using 200 equally spaced starting values between $-\pi$ and $\pi$.
The results are 
Partition
the values into sets of attraction, That is, divide the set of starting values into separate
groups, with each group corresponding to a separate unique outcome of the optimization

## Problem 3
**Answer:** 


The model for population growth is given by $\frac{{dN}}{{dt}} = rN(1 - \frac{N}{K})$.
The solution of this is 
${N_t} = f(t){\rm{ }} = \frac{{K{N_0}}}{{{N_0} + (K - {N_0}){\rm{ }}exp( - rt)}}$

a)
b)
c)
